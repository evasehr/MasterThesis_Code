{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation of dataframe by selection of 10k random SNPs from all 7 locations for NN analyses\n",
    "\n",
    "The following locations are considered:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| longitude | latitude | country | nearest neighbour accession |\n",
    "| --- | --- | --- | :---: |\n",
    "| 36.76539 | -5.499419 | Andalucia | 1600 |\n",
    "| 51.49702 | 11.970655 | Germany | 1059 |\n",
    "| 65.00307 | 25.472679 | Finland | 309 |\n",
    "| 39.48083 | -0.340985 | Spain| 1576|\n",
    "| 52.62779 | 1.293458 | UK | 578 |\n",
    "| 48.544886 | 9.043042 | Tuebingen | 1813 |\n",
    "| 40.408049 | -3.83535 | Madrid | 1845 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set(color_codes=True)\n",
    "sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
    "pd.set_option('display.max_columns', 999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select specific SNPs\n",
    "Selection of 10k random SNPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas = pd.read_csv('/Carnegie/DPB/Data/Shared/Labs/Moi/Everyone/deepselection/randomForest/betas_woNAs_55climvars_rFit.txt', sep='\\t')\n",
    "betas.rename(columns={'clim-bio18.assoc_y':'clim-bio18'}, inplace=True)\n",
    "betas.drop(['clim-bio18.assoc_x'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas2 = pd.read_csv('/Carnegie/DPB/Data/Shared/Labs/Moi/Everyone/deepselection/randomForest/betas_woNAs_Fitness.txt', sep='\\t')\n",
    "betas2.rename(columns={'Fitness_Andaluci':'Fitness_Andalucia'}, inplace=True)\n",
    "betas2 = betas2[betas2.columns.drop(list(betas2.filter(regex='randomized')))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = pd.merge(betas2, betas, on='rs')\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomSNPs = pd.read_csv('/Carnegie/DPB/Data/Shared/Labs/Moi/Everyone/deepselection/randomForest/randomSNPsList.txt', sep='\\t')\n",
    "randomSNPs = randomSNPs['randomSNPs'].tolist()\n",
    "\n",
    "total.set_index('rs')\n",
    "\n",
    "randomDF = total.loc[total['rs'].isin(randomSNPs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP = randomDF[['rs', 'rFitness2_mlp']].copy()\n",
    "MLP.rename(columns={'rFitness2_mlp':'beta'}, inplace=True)\n",
    "MLP['locat'] = 'MLP'\n",
    "\n",
    "MLI = randomDF[['rs', 'rFitness2_mli']].copy()\n",
    "MLI.rename(columns={'rFitness2_mli':'beta'}, inplace=True)\n",
    "MLI['locat'] = 'MLI'\n",
    "\n",
    "THI = randomDF[['rs', 'rFitness2_thi']].copy()\n",
    "THI.rename(columns={'rFitness2_thi':'beta'}, inplace=True)\n",
    "THI['locat'] = 'THI'\n",
    "\n",
    "THP = randomDF[['rs', 'rFitness2_thp']].copy()\n",
    "THP.rename(columns={'rFitness2_thp':'beta'}, inplace=True)\n",
    "THP['locat'] = 'THP'\n",
    "\n",
    "AND = randomDF[['rs', 'Fitness_Andalucia']].copy()\n",
    "AND.rename(columns={'Fitness_Andalucia':'beta'}, inplace=True)\n",
    "AND['locat'] = 'AND'\n",
    "\n",
    "SPA = randomDF[['rs', 'Fitness_Spain']].copy()\n",
    "SPA.rename(columns={'Fitness_Spain':'beta'}, inplace=True)\n",
    "SPA['locat'] = 'SPA'\n",
    "\n",
    "UKI = randomDF[['rs', 'Fitness_UnitedKingdom']].copy()\n",
    "UKI.rename(columns={'Fitness_UnitedKingdom':'beta'}, inplace=True)\n",
    "UKI['locat'] = 'UKI'\n",
    "\n",
    "FIN = randomDF[['rs', 'Fitness_Finland']].copy()\n",
    "FIN.rename(columns={'Fitness_Finland':'beta'}, inplace=True)\n",
    "FIN['locat'] = 'FIN'\n",
    "\n",
    "GER = randomDF[['rs', 'Fitness_Germany']].copy()\n",
    "GER.rename(columns={'Fitness_Germany':'beta'}, inplace=True)\n",
    "GER['locat'] = 'GER'\n",
    "GER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = pd.DataFrame(data=MLP)\n",
    "target = target.append([MLI, THP, THI, AND, FIN, GER, SPA, UKI], ignore_index=True, sort=False)\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count total number of NaNs\n",
    "target.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target.to_csv(r'Input/Target_randomSNPs.csv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tarMLP = target[target[\"locat\"] == 'MLP']\n",
    "tarMLP #0-9995"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tarMLI = target[target[\"locat\"] == 'MLI']\n",
    "tarMLI #9996-19991"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tarTHP = target[target[\"locat\"] == 'THP']\n",
    "tarTHP #19992-29987"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tarTHI = target[target[\"locat\"] == 'THI']\n",
    "tarTHI #29988-39983"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tarSPA = target[target[\"locat\"] == 'SPA']\n",
    "tarSPA #69972-79967"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tarUKI = target[target[\"locat\"] == 'UKI']\n",
    "tarUKI #79968-89963"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tarGER = target[target[\"locat\"] == 'GER']\n",
    "tarGER #59976-69971"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tarFIN = target[target[\"locat\"] == 'FIN']\n",
    "tarFIN #49980-59975"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tarAND = target[target[\"locat\"] == 'AND']\n",
    "tarAND #39984-49979"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = pd.concat([randomDF]*9, ignore_index=True)\n",
    "predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add annotation to predictors dataset\n",
    "annot = pd.read_csv(f'/Carnegie/DPB/Data/Shared/Labs/Moi/Everyone/deepselection/randomForest/515g2.ann.txt', sep='\\t')\n",
    "predictors = predictors.join(annot.set_index('rs'), on='rs')\n",
    "predictors = predictors.drop(columns=['chr', 'ps', 'allel1', 'allel2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode annotation numerically\n",
    "lb = LabelEncoder()\n",
    "predictors['ann'] = lb.fit_transform(predictors['ann'])\n",
    "\n",
    "# print encoding\n",
    "lbMapping = dict(zip(lb.classes_, lb.transform(lb.classes_)))\n",
    "lbMapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare climate data \n",
    "\n",
    "clim = pd.read_csv(f'/Carnegie/DPB/Data/Shared/Labs/Moi/Everyone/natvar/climate/2029gclimate.tsv', delim_whitespace=True)\n",
    "\n",
    "climT = pd.concat([clim.iloc[[1813]]]*int(len(predictors)/9*2), ignore_index=True) #1813 = accession close to Tübingen\n",
    "climM = pd.concat([clim.iloc[[1845]]]*int(len(predictors)/9*2), ignore_index=True) #1845 = accession close to Madrid\n",
    "\n",
    "climA = pd.concat([clim.iloc[[1600]]]*int(len(predictors)/9), ignore_index=True) #1600 = accession close to location Andalusia\n",
    "climG = pd.concat([clim.iloc[[1059]]]*int(len(predictors)/9), ignore_index=True) #1059 = accession close to location Germany\n",
    "climF = pd.concat([clim.iloc[[309]]]*int(len(predictors)/9), ignore_index=True) #309 = accession close to location Finland\n",
    "climS = pd.concat([clim.iloc[[1576]]]*int(len(predictors)/9), ignore_index=True) #1576 = accession close to location Spain\n",
    "climU = pd.concat([clim.iloc[[578]]]*int(len(predictors)/9), ignore_index=True) #578 = accession close to location United Kingdom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "climFin = pd.concat([climM, climT, climA,  climF, climG, climS, climU], axis=0) #concat this way, to have Madrid at first, then Tübingen and then in alphabetic order to fit to target order\n",
    "climFin = climFin.iloc[:, :-12]    \n",
    "climFin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finalize predictors dataset\n",
    "predictors = pd.concat([predictors.reset_index(drop=True), climFin.reset_index(drop=True)], axis=1, sort=False)  # without reset_index, NAs were introduced in DF\n",
    "cols=[1,2,3,4,5,6,7,8,9]    #drop rFitness columns\n",
    "predictors = predictors.drop(predictors.columns[cols], axis=1)\n",
    "predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors.to_csv(r'Input/Predictors_randomSNPs.csv', sep='\\t', index=False).ipynb_checkpoints/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
