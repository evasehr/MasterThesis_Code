{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NNPT-7-Chr1-HL10\n",
    "## NN using PyTorch, 7 environments, Chromosome 1 as cross validation set, 10 hidden layers (decreasing size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set(color_codes=True)\n",
    "sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
    "pd.set_option('display.max_columns', 999)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = pd.read_csv('Input/Predictors_7locs.csv', delim_whitespace=True)\n",
    "target = pd.read_csv('Input/Target_7locs.csv', delim_whitespace=True)\n",
    "\n",
    "entire = pd.concat([predictors.reset_index(drop=True), target.reset_index(drop=True)], axis=1, sort=False)\n",
    "entire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical columns to category dtypes.\n",
    "cat_cols = ['ann']\n",
    "for cat in cat_cols:\n",
    "    entire[cat] = entire[cat].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all entries from the chromosome that is later used for Cross Validation\n",
    "chr = \"1_\"\n",
    "\n",
    "# remove first column since anyway a duplicate\n",
    "entire2 = entire.iloc[:,1:]\n",
    "entire2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chr1 = entire2[entire2.rs.str.contains('1_',case=False)]\n",
    "chr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chr1bool = entire2['rs'].str.contains(chr)\n",
    "rest = entire2[~chr1bool]\n",
    "rest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = rest['rFitness']\n",
    "X_train = rest.iloc[:, :-3].copy()    # without rs and fitness column\n",
    "X_train;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = chr1['rFitness']\n",
    "X_test = chr1.iloc[:, :-3].copy()\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical columns to category dtypes.\n",
    "for cat in cat_cols:\n",
    "    X_test[cat] = X_test[cat].astype('category')\n",
    "    X_train[cat] = X_train[cat].astype('category')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare dataset for plotting\n",
    "y_testlocat = y_test.copy()\n",
    "y_testlocat = y_testlocat.reset_index()\n",
    "\n",
    "#tarUKI 131896-148382\n",
    "#tarSPA 115409-131895\n",
    "#tarFIN 98922-115408\n",
    "#tarGER 82435-98921\n",
    "#tarAND 65948-82434\n",
    "#tarTHI #49461 -65947\n",
    "#tarTHP #32974-49460\n",
    "#tarMLI # 16487-32973\n",
    "#tarMLP #0-16486\n",
    "\n",
    "y_testlocat['locat'] = ['MLP' if 0 <=x<= 16486 else \n",
    "                        'MLI' if 16487 <=x<= 32973 else \n",
    "                        'THP' if 32974 <=x<= 49460 else \n",
    "                        'THI' if 49461 <=x<= 65947 else\n",
    "                        'AND' if 65948 <=x<= 82434 else\n",
    "                        'GER' if 82435 <=x<= 98921 else\n",
    "                        'FIN' if 98922 <=x<= 115408 else\n",
    "                        'SPA' if 115409 <=x<= 131895 else\n",
    "                        'UKI' for x in y_testlocat['index']]\n",
    "y_testlocat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_col = ['rFitness']\n",
    "X_col = [col for col in X_train.columns if col not in cat_cols + y_col]\n",
    "cont_cols = [col for col in X_col if col not in cat_cols + y_col]\n",
    "cont_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats_train = X_train['ann'].values \n",
    "cats_test = X_test['ann'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert categorical vars to tensor\n",
    "#cats = torch.tensor(cats, dtype=torch.int64) #old version\n",
    "cats_train = torch.tensor(cats_train, dtype=torch.int64).reshape(-1,1) #new version because of errors in model\n",
    "cats_test = torch.tensor(cats_test, dtype=torch.int64).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats_train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cats_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert continuous variables to a tensor\n",
    "#conts = np.stack([x[col].values for col in cont_cols], 1) #exchange rest to entire (16.9)\n",
    "conts_train = np.stack([X_train[col].values for col in cont_cols], 1)\n",
    "conts_test = np.stack([X_test[col].values for col in cont_cols], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(conts_train)\n",
    "conts_train = scaler.transform(conts_train)\n",
    "conts_test = scaler.transform(conts_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conts_train = torch.tensor(conts_train, dtype=torch.float)\n",
    "conts_test = torch.tensor(conts_test, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conts_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conts_train[:3];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(conts_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(conts_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to a tensor\n",
    "#y = torch.tensor(entire[y_col].values, dtype=torch.float).reshape(-1,1) #exchange rest to entire (16.9)\n",
    "y_train = torch.tensor(y_train.to_numpy(dtype=np.float64)).reshape(-1,1)\n",
    "y_test = torch.tensor(y_test.to_numpy(dtype=np.float64)).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will set embedding sizes for categorical variables\n",
    "cat_szs = [len(entire[col].cat.categories) for col in cat_cols]\n",
    "emb_szs = [(size, min(50, (size+1)//2)) for size in cat_szs]\n",
    "emb_szs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabularModel(nn.Module):\n",
    "\n",
    "    def __init__(self, emb_szs, n_cont, out_sz, layers, p=0.5):\n",
    "        super().__init__()\n",
    "        self.embeds = nn.ModuleList([nn.Embedding(ni, nf) for ni,nf in emb_szs])\n",
    "        self.emb_drop = nn.Dropout(p)\n",
    "        self.bn_cont = nn.BatchNorm1d(n_cont)\n",
    "        \n",
    "        layerlist = []\n",
    "        n_emb = sum((nf for ni,nf in emb_szs))\n",
    "        n_in = n_emb + n_cont\n",
    "        \n",
    "        for i in layers:\n",
    "            layerlist.append(nn.Linear(n_in,i)) \n",
    "            layerlist.append(nn.ReLU(inplace=True))\n",
    "            layerlist.append(nn.BatchNorm1d(i))\n",
    "            layerlist.append(nn.Dropout(p))\n",
    "            n_in = i\n",
    "        layerlist.append(nn.Linear(layers[-1],out_sz))\n",
    "            \n",
    "        self.layers = nn.Sequential(*layerlist)\n",
    "    \n",
    "    def forward(self, x_cat, x_cont):\n",
    "        embeddings = []\n",
    "        for i,e in enumerate(self.embeds):\n",
    "            embeddings.append(e(x_cat[:,i])) #because of error, changed from originally (e(x_cat[:,i])) to (e(x_cat[i]))\n",
    "        x = torch.cat(embeddings,1) #changed from (embeddings, 1) to (embeddings)\n",
    "        x = self.emb_drop(x)\n",
    "        \n",
    "        x_cont = self.bn_cont(x_cont)\n",
    "        x = torch.cat([x, x_cont],1)\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "model = TabularModel(emb_szs, conts_train.shape[1], 1, [100, 90, 80, 70, 60, 50, 40, 30, 20, 10], p=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "epochs = 400\n",
    "losses = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    i+=1\n",
    "    y_pred = model(cats_train, conts_train).double() #had to include .double() because of error\n",
    "    loss = torch.sqrt(criterion(y_pred, y_train)) # RMSE\n",
    "    losses.append(loss)\n",
    "    \n",
    "    # a neat trick to save screen space:\n",
    "    if i%25 == 1:\n",
    "        print(f'epoch: {i:3}  loss: {loss.item():10.8f}')\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(f'epoch: {i:3}  loss: {loss.item():10.8f}') # print the last line\n",
    "print(f'\\nDuration: {time.time() - start_time:.0f} seconds') # print the time elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(13,10)})\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.plot(range(epochs), losses)\n",
    "plt.title(\"RMSE loss\", size= 20, pad=25)\n",
    "#plt.suptitle(\"RMSE loss\", size = 20)\n",
    "plt.xlabel(\"Epoch\", size=16)\n",
    "plt.ylabel(\"RMSE\", size=16)\n",
    "#plt.savefig('Output/09CVchr_RMSEloss.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVALUATE Training set\n",
    "with torch.no_grad():\n",
    "    y_pred_train= model(cats_train, conts_train)\n",
    "    loss = torch.sqrt(criterion(y_pred_train, y_train)) # RMSE\n",
    "print(f'RMSE of training set: on average, the predicted values are within +/- {loss:.8f} (RMSE) of the actual value.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "# sklearn.metrics.r2_score(y_true, y_pred, *, sample_weight=None, multioutput='uniform_average')[source]\n",
    "print(\"R2 score: \", r2_score(y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  EVALUATE TEST SET\n",
    "with torch.no_grad():\n",
    "    y_pred_test = model(cats_test, conts_test)\n",
    "    loss = torch.sqrt(criterion(y_test, y_pred_test))\n",
    "print(f'RMSE: on average, the predicted values are within +/- {loss:.8f} (RMSE) of the actual value.')\n",
    "print(\"R2 score: \", r2_score(y_test,y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{\"PREDICTED\":>12} {\"ACTUAL\":>8} {\"DIFF\":>8}')\n",
    "for i in range(50):\n",
    "    diff = np.abs(y_pred_test[i].item()-y_test[i].item())\n",
    "    print(f'{i+1:2}. {y_pred_test[i].item():8.4f} {y_test[i].item():8.4f} {diff:8.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting predictions from tensor objects into a list\n",
    "y_pred_test2plot = [y_pred_test[x].item() for x in range(len(y_pred_test))]\n",
    "y_test2plot = [y_test[x].item() for x in range(len(y_test))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing actual and predicted values\n",
    "df = {}\n",
    "df['Actual values'] = y_test2plot\n",
    "df['Predicted values'] = y_pred_test2plot\n",
    "df['Location'] = y_testlocat['locat'] ##check\n",
    "df = pd.DataFrame(df)\n",
    "df.to_csv('Output/09_pytorch_CVchr_predictedValues.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Output/09_pytorch_CVchr_predictedValues.csv')\n",
    "df = df.sort_values('Location')\n",
    "\n",
    "# Order AND       FIN        GER       MLI        MLP        SPA        THI        THP          UKI\n",
    "col =['#008cf9','#878500','#00bbad', '#006e00', '#984ea3', '#ff9287', '#b80058', '#ebac23', '#5954d6']\n",
    "\n",
    "sns.set(rc={'figure.figsize':(13,10)})\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(col)\n",
    "s = sns.scatterplot(x='Predicted values', y='Actual values', hue='Location', sizes=(20), data=df) \n",
    "plt.title(\"Neural network | PyTorch | 1,000 - 1,000 SNPs\", size= 16, pad=25)\n",
    "plt.suptitle(\"Actual vs predicted selection coefficients from all locations of chromosome 1\", size = 20)\n",
    "#plt.ylim(min(entire['rFitness']),max(entire['rFitness']))\n",
    "plt.xlim(-1,3)\n",
    "plt.ylim(-1,3)\n",
    "plt.xlabel(\"Predicted\", size=16)\n",
    "plt.ylabel(\"Actual\", size=16)\n",
    "plt.setp(s.get_legend().get_texts(), fontsize='16') # for legend text\n",
    "plt.setp(s.get_legend().get_title(), fontsize='18') # for legend title\n",
    "#plt.savefig('Output/09chrCV_PredActual.png', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values('Location')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order AND       FIN        GER       MLI        MLP        SPA        THI        THP          UKI\n",
    "col =['#008cf9','#878500','#00bbad', '#006e00', '#984ea3', '#ff9287', '#b80058', '#ebac23', '#5954d6']\n",
    "\n",
    "# plot separated\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(col)\n",
    "\n",
    "p =sns.relplot(\n",
    "    data=df, x='Predicted values', y='Actual values',\n",
    "    col=\"Location\", hue=\"Location\",\n",
    "    kind=\"scatter\", col_wrap=5)\n",
    "plt.subplots_adjust(top=0.9)\n",
    "p.fig.suptitle(\" NNSL-7-Chr1-HL10 | Actual vs predicted selection coefficients from all locations of chromosome 1\", size = 20)\n",
    "\n",
    "#plt.savefig('Output/09chrCV_PredActual_grid.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure to save the model only after the training has happened!\n",
    "if len(losses) == epochs:\n",
    "    torch.save(model.state_dict(), 'pytorch_model_Chr1CV2.pt')\n",
    "else:\n",
    "    print('Model has not been trained. Consider loading a trained model instead.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
