{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RF based on 500 selected SNPs from positive tail of distribution of rel. fitness betas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 999)\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Settings for seaborn\n",
    "sns.set(color_codes=True)\n",
    "sns.set(rc={'figure.figsize':(11.7,8.27)})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select specific SNPs\n",
    "Select 500 SNPs from positive tail of selection coefficient distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas = pd.read_csv('/Carnegie/DPB/Data/Shared/Labs/Moi/Everyone/deepselection/randomForest/betas_woNAs_55climvars_rFit.txt', sep='\\t')\n",
    "betas.rename(columns={'clim-bio18.assoc_y':'clim-bio18'}, inplace=True)\n",
    "betas.drop(['clim-bio18.assoc_x'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract mlp and mli datasets\n",
    "MLP = betas[['rs', 'rFitness2_mlp']]\n",
    "MLI = betas[['rs', 'rFitness2_mli']]\n",
    "THP = betas[['rs', 'rFitness2_thp']]\n",
    "THI = betas[['rs', 'rFitness2_thi']]\n",
    "THI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check distribution of betas from GWAS to rel. Fitness\n",
    "\n",
    "a = MLP['rFitness2_mlp']\n",
    "b = MLI['rFitness2_mli']\n",
    "c = THP['rFitness2_thp']\n",
    "d = THI['rFitness2_thi']\n",
    "\n",
    "sns.set()\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(1,4, figsize = (24, 6))\n",
    "fig.suptitle('Distribution of betas from GWAS to fitness') \n",
    "sns.distplot(a, ax=ax1)\n",
    "sns.distplot(b, ax=ax2)\n",
    "sns.distplot(c, ax=ax3)\n",
    "sns.distplot(d, ax=ax4)\n",
    "ax1.set_xlabel('MLP')\n",
    "ax2.set_xlabel('MLI')\n",
    "ax3.set_xlabel('THP')\n",
    "ax4.set_xlabel('THI')\n",
    "fig.show()\n",
    "#fig.savefig('Output/03_BetasDist.png', bbox_inches='tight', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort & select\n",
    "MLP = MLP.sort_values(by=['rFitness2_mlp'], ascending=False)\n",
    "MLI = MLI.sort_values(by=['rFitness2_mli'], ascending=False)\n",
    "THP = THP.sort_values(by=['rFitness2_thp'], ascending=False)\n",
    "THI = THI.sort_values(by=['rFitness2_thi'], ascending=False)\n",
    "\n",
    "# get the first and last 1000 objects (highest and lowest betas)\n",
    "selMLP = MLP.iloc[:500, :]   \n",
    "#selMLP = selMLP.append(MLP.iloc[-500:, :])\n",
    "selMLPSNPs = selMLP['rs'].tolist()\n",
    "\n",
    "selMLI = MLI.iloc[:500, :]   \n",
    "#selMLI = selMLI.append(MLI.iloc[-500:, :])\n",
    "selMLISNPs = selMLI['rs'].tolist()\n",
    "\n",
    "selTHP = THP.iloc[:500, :]   \n",
    "#selTHP = selTHP.append(THP.iloc[-500:, :])\n",
    "selTHPSNPs = selTHP['rs'].tolist()\n",
    "\n",
    "selTHI = THI.iloc[:500, :]   \n",
    "#selTHI = selTHI.append(THI.iloc[-500:, :])\n",
    "selTHISNPs = selTHI['rs'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selTHI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check distribution of selection\n",
    "\n",
    "a = selMLP['rFitness2_mlp']\n",
    "b = selMLI['rFitness2_mli']\n",
    "c = selTHP['rFitness2_thp']\n",
    "d = selTHI['rFitness2_thi']\n",
    "\n",
    "sns.set()\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(1,4, figsize = (24, 6))\n",
    "fig.suptitle('Distribution of selected betas from GWAS to fitness') \n",
    "sns.distplot(a, ax=ax1)\n",
    "sns.distplot(b, ax=ax2)\n",
    "sns.distplot(c, ax=ax3)\n",
    "sns.distplot(d, ax=ax4)\n",
    "ax1.set_xlabel('MLP')\n",
    "ax2.set_xlabel('MLI')\n",
    "ax3.set_xlabel('THP')\n",
    "ax4.set_xlabel('THI')\n",
    "fig.show()\n",
    "#fig.savefig('Output/03_SelBetasDist.png', bbox_inches='tight', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use all rs from the selection above and create new list\n",
    "mySNPs = selMLPSNPs + selMLISNPs + selTHPSNPs + selTHISNPs\n",
    "len(mySNPs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for duplicates\n",
    "from collections import Counter\n",
    "[k for k,v in Counter(mySNPs).items() if v>1]\n",
    "len(mySNPs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicates\n",
    "mySNPs = list(set(mySNPs))\n",
    "\n",
    "# check again for duplicates\n",
    "from collections import Counter\n",
    "[k for k,v in Counter(mySNPs).items() if v>1]\n",
    "len(mySNPs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create now target dataframe with selected SNPs\n",
    "\n",
    "target = pd.DataFrame(mySNPs, columns=['rs'])\n",
    "\n",
    "a = target.join(MLP.set_index('rs'), on='rs')\n",
    "a.rename(columns={'rFitness2_mlp':'rFitness'}, inplace=True)\n",
    "a['locat'] = 'MLP'\n",
    "\n",
    "b = target.join(MLI.set_index('rs'), on='rs')\n",
    "b.rename(columns={'rFitness2_mli':'rFitness'}, inplace=True)\n",
    "b['locat'] = 'MLI'\n",
    "\n",
    "c = target.join(THP.set_index('rs'), on='rs')\n",
    "c.rename(columns={'rFitness2_thp':'rFitness'}, inplace=True)\n",
    "c['locat'] = 'THP'\n",
    "\n",
    "d = target.join(THI.set_index('rs'), on='rs')\n",
    "d.rename(columns={'rFitness2_thi':'rFitness'}, inplace=True)\n",
    "d['locat'] = 'THI'\n",
    "\n",
    "target = a.append([b, c, d], ignore_index=True, sort=False)\n",
    "target = target.reset_index()\n",
    "target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tarMLP = target[target[\"locat\"] == 'MLP']\n",
    "tarMLP #index0-1975\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tarMLI = target[target[\"locat\"] == 'MLI']\n",
    "tarMLI #index 1976-3951"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tarTHP = target[target[\"locat\"] == 'THP']\n",
    "tarTHP #index 3952-5927"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tarTHI = target[target[\"locat\"] == 'THI']\n",
    "tarTHI #index 5928-7903"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check distribution of target\n",
    "sns.distplot(target['rFitness'])\n",
    "plt.xlabel('Combined beta values as target variable')\n",
    "plt.title('Distribution of target')\n",
    "#plt.savefig('Output/03_TargetVarDist.png', bbox_inches='tight', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = pd.DataFrame(mySNPs, columns=['rs'])\n",
    "predictors = predictors.join(betas.set_index('rs'), on='rs')\n",
    "cols=[1,2,3,4]    #drop rFitness columns\n",
    "predictors = predictors.drop(predictors.columns[cols], axis=1)\n",
    "predictors = pd.concat([predictors]*4, ignore_index=True)\n",
    "predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add annotation to predictors dataset\n",
    "annot = pd.read_csv(f'/Carnegie/DPB/Data/Shared/Labs/Moi/Everyone/deepselection/randomForest/515g2.ann.txt', sep='\\t')\n",
    "predictors = predictors.join(annot.set_index('rs'), on='rs')\n",
    "predictors = predictors.drop(columns=['chr', 'ps', 'allel1', 'allel2'])\n",
    "predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(predictors)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode annotation numerically\n",
    "lb = LabelEncoder()\n",
    "predictors['ann'] = lb.fit_transform(predictors['ann'])\n",
    "\n",
    "# print encoding\n",
    "lbMapping = dict(zip(lb.classes_, lb.transform(lb.classes_)))\n",
    "lbMapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare climate data \n",
    "\n",
    "clim = pd.read_csv(f'/Carnegie/DPB/Data/Shared/Labs/Moi/Everyone/natvar/climate/2029gclimate.tsv', delim_whitespace=True)\n",
    "climT = pd.concat([clim.iloc[[1813]]]*int(len(predictors)/2), ignore_index=True) #1813 = accession close to Tübingen\n",
    "climM = pd.concat([clim.iloc[[1845]]]*int(len(predictors)/2), ignore_index=True) #1845 = accession close to Madrid\n",
    "climFin = pd.concat([climM, climT], axis=0) #concat this way, to have Madrid at first, then Tübingen\n",
    "climFin = climFin.iloc[:, :-12]    \n",
    "climFin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finalize predictors dataset\n",
    "predictors = pd.concat([predictors.reset_index(drop=True), climFin.reset_index(drop=True)], axis=1, sort=False)  # without reset_index, NAs were introduced in DF\n",
    "predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check distribution of predictors\n",
    "\n",
    "a = predictors['ann']\n",
    "b = predictors['bio1']\n",
    "c = predictors['clim-bio1']\n",
    "\n",
    "sns.set()\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1,3, figsize = (24, 6))\n",
    "fig.suptitle('Distribution of beta values from selected predictor variables') \n",
    "sns.distplot(a, ax=ax1)\n",
    "sns.distplot(b, ax=ax2)\n",
    "sns.distplot(c, ax=ax3)\n",
    "ax1.set_xlabel('Annotation')\n",
    "ax2.set_xlabel('Worldclim | bio1')\n",
    "ax3.set_xlabel('Betas | bio1')\n",
    "fig.show()\n",
    "#ig.savefig('Output/03_PredVarDist.png', bbox_inches='tight', dpi=600)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "### Input variable preparation and distribution plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = target['rFitness']\n",
    "X = predictors.iloc[:, 1:].copy()    # without rs column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import QuantileTransformer, quantile_transform\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "from yellowbrick.regressor import PredictionError, ResidualsPlot\n",
    "from yellowbrick.features import Rank1D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit regression model\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "regr_rf = RandomForestRegressor(oob_score=True, random_state=0, n_estimators = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test2plot = y_test.copy()\n",
    "y_test2plot = y_test2plot.reset_index()\n",
    "y_test2plot['locat'] = ''\n",
    "y_test2plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test2plot['locat'] = ['MLP' if 0 <= x <= 1975 else 'MLI' if 1976 <= x <= 3951 else 'THP' if 3952 <= x <= 5927 else 'THI' for x in y_test2plot['index']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test2plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "regr_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "y_rf = regr_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_train = regr_rf.predict(X_train)\n",
    "predicted_test = regr_rf.predict(X_test)\n",
    "test_score = r2_score(y_test, predicted_test)\n",
    "spearman = spearmanr(y_test, predicted_test)\n",
    "pearson = pearsonr(y_test, predicted_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics --> printed to file\n",
    "print('Mean Absolute Error (MAE):', metrics.mean_absolute_error(y_test, y_rf), file=open('Output/03_Metrics.txt', 'a'))\n",
    "print('Mean Squared Error (MSE):', metrics.mean_squared_error(y_test, y_rf), file=open('Output/03_Metrics.txt', 'a'))\n",
    "print('Root Mean Squared Error (RMSE):', np.sqrt(metrics.mean_squared_error(y_test, y_rf)), file=open('Output/03_Metrics.txt', 'a'))\n",
    "\n",
    "print('Further statistics:', file=open('Output/03_Metrics.txt', 'a'))\n",
    "print(f'Out-of-bag R2 score estimate: {regr_rf.oob_score_:>5.3}', file=open('Output/03_Metrics.txt', 'a'))\n",
    "print(f'Test data R2 score: {test_score:>5.3}', file=open('Output/03_Metrics.txt', 'a'))\n",
    "print(f'Test data Spearman correlation: {spearman[0]:.3}', file=open('Output/03_Metrics.txt', 'a'))\n",
    "print(f'Test data Pearson correlation: {pearson[0]:.3}', file=open('Output/03_Metrics.txt', 'a'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot results with Yellowbrick\n",
    "https://www.scikit-yb.org/en/latest/api/regressor/peplot.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residuals plot\n",
    "f = plt.figure()\n",
    "visualizer = ResidualsPlot(regr_rf)\n",
    "visualizer.fit(X_train, y_train)\n",
    "visualizer.score(X_test, y_test)\n",
    "visualizer.show()\n",
    "#f.savefig(\"Output/03_Residuals.png\", bbox_inches='tight', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction error plot\n",
    "f = plt.figure()\n",
    "visualizer = PredictionError(regr_rf)\n",
    "visualizer.fit(X_train, y_train)\n",
    "visualizer.score(X_test, y_test)\n",
    "visualizer.show()\n",
    "#f.savefig(\"Output/03_PredActual.png\", bbox_inches='tight', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_rf2plot = pd.DataFrame(y_rf)\n",
    "df2plot = pd.concat([y_test2plot, y_rf2plot], axis=1)\n",
    "df2plot.columns = ['index', 'actual', 'location', 'pred']\n",
    "df2plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_palette('Paired')\n",
    "sns.scatterplot(x='actual', y='pred', hue='location', data=df2plot)\n",
    "plt.title(\"Actual vs predicted beta values\")\n",
    "plt.xlabel(\"Actual\")\n",
    "plt.ylabel(\"Predicted\")\n",
    "#lt.savefig('Output/03_PredActual_Color.png', bbox_inches='tight', dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature importance:\n",
    "https://machinelearningmastery.com/calculate-feature-importance-with-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = regr_rf.feature_importances_         # get importance\n",
    "\n",
    "# summarize feature importance\n",
    "#for i,v in enumerate(importance):\n",
    "#\tprint('Feature: %0d, Score: %.5f' % (i,v))\n",
    "\n",
    "labels = list(X.columns.values)\n",
    "\n",
    "plt.figure(figsize=(18,8))\n",
    "imp = sns.barplot([x for x in range(len(importance))], importance)\n",
    "imp.set_xticklabels(labels,  rotation='vertical')\n",
    "plt.title(\"Feature importance\")\n",
    "#plt.savefig('Output/03_Features.png', bbox_inches='tight', dpi=600)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
